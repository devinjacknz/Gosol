# Environment
ENVIRONMENT=development
LOG_LEVEL=info

# LLM Configuration
OLLAMA_BASE_URL=http://localhost:11434
DEEPSEEK_API_KEY=your-api-key
DEEPSEEK_BASE_URL=https://api.deepseek.com

# Model Configuration
DEFAULT_MODEL=deepseek-coder:1.5b
FALLBACK_MODEL=llama2
CONTEXT_SIZE=4096
RESPONSE_FORMAT=json

# Performance
MAX_CONCURRENT_REQUESTS=5
REQUESTS_PER_SECOND=10
HTTP_TIMEOUT_SECONDS=30
STREAM_TIMEOUT_SECONDS=60

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=2112
METRICS_PATH=/metrics

# Security
ENABLE_RATE_LIMIT=true
ENABLE_REQUEST_VALIDATION=true
MAX_REQUEST_SIZE_MB=10 